#! /bin/bash

# $1 number of first event to prepare
# $2 number of last event
# $3 run SONIC?
# $4 run Txt2Hist?
# $5 run Diffusion?

# setup_events.sh will setup $2-$1 events in the directory it is executed in. For event$i, it will create the directory event$i, in which all of the processing will occur.
# The main script and code will be copied over and should be modified to match the params.txt file, which should be modified in turn to match the initial conditions.
# This includes changing the system "SPC", number of bins, but also the grid spacing/grid size, nucleon-nucleon cross-section. The smoothing option is also important for 
# larger systems with lumpy initial conditions, e.g. He3+Au or He4+Au.
# The files that need to be appropriately modified:
#   condor_run.csh
#   Txt2Hist.C: values for N
#   diffusion.C: values for NGridX, NGridY should be modified (see TODO)
#   params.txt: values for SIGMANN, NUMT, AT, SNAPUPDATE should be modified
#   this one: user-defined directories should be changed (see TODO)
#   

# Description of each file:

#   inited_specified_template is a template directory for running sonic. To run a full event through diffusion, several files need to be copied into the event directory. Several of these are taken care of below, but a few (such as Txt2Hist.C or params.txt) should be modified to match the desired run parameters.

#   condor_run.csh is the primary driver script. It executes each module in the correct order, organizing input files appropriately and copying over needed file. If a custom file (such as an initial condition) is provided, a line in condor_run.csh can be added to copy over the corresponding .dat file. (Alternatively, of course, you can modify the line below to copy over the .dat file when instantiating the event.) Other files, like diffusion.C and Txt2Hist.C, are copied at run time from the parent directory so that necessary changes can be made once and propagate to all events.

#   init, generate, vh2, b3d, and b3d-analyze are the main sonic routines. b3d requires access to hdf5, which is installed on my own home directory ~jouellette/ and should be publically accessible. These are setup to output in the subdirectory event$i/logdir. vh2 is the most intensive since it runs the main hydro evolution. It can be monitored in the log file by controlling the UPDATE parameter in params.txt.

#   Txt2Hist.C is meant to be run after the entire sonic routine has been completed. It takes the output from vh2 and generates a root file from the FOdata, Tcontour, and (optionally) EDprofile with temperature and fluid velocity distributions at each timestep which is intended for use in the diffusion routine.

#   diffusion.C is meant to be run after Txt2Hist.C. As input, it requires several different pieces of information. Primarily, it requires the hydro output which comes from Txt2Hist.C. It also needs a pT spectrum for heavy quarks (this can be used defined or generated in Pythia - heavy_quark_pt.root is the default pT spectrum and is provided here, however it only contains a ccbar pT spectrum but ideally a bbbar will be added soon). Lastly, it requires a wounded nucleon distribution (the initial energy density should be fine as a root file) as well as the name of the distribtion as a TH2D.

#   heavy_quark_pt.root contains the heavy quark initial pT spectra. This was generated by forcing ccbar pair creation in Pythia, and plotting their pT values.

#   params.txt is the primary parameters file used by sonic. There are several values in this file that need to be modified for sonic to run correctly, as listed above.



dir=`pwd`
sys=He3Au
echo "Setting up '$(($2-$1))' event(s) in $dir..."

echo "Universe = vanilla" > submit_events.job
echo "Notification = Complete" >> submit_events.job
echo "Executable = $dir/condor_run.csh" >> submit_events.job
echo "Requirements = (CPU_Speed >= 1 && CPU_Experiment == \"phenix\")" >> submit_events.job
echo "Rank = CPU_Speed" >> submit_events.job
echo "Priority = +1" >> submit_events.job
echo "GetEnv = False" >> submit_events.job
echo "InitialDir = $dir" >> submit_events.job
echo "Error = $dir/log/job_\$(Process)/job_\$(Process).err" >> submit_events.job
echo "Log = $dir/log/job_\$(Process)/job_\$(Process).log" >> submit_events.job
echo "Output = $dir/log/job_\$(Process)/job_\$(Process).out" >> submit_events.job
echo "Notify_user = jeffrey.ouellette@colorado.edu" >> submit_events.job #TODO change me!!!
echo "+Experiment = \"phenix\"" >> submit_events.job
echo "+Job_Type = \"cas\"" >> submit_events.job

cp -n /sphenix/user/jouellette/HHQTemplate/condor_run.csh ./condor_run.csh
cp -n /sphenix/user/jouellette/HHQTemplate/Txt2Hist.C ./Txt2Hist.C 
cp -n /sphenix/user/jouellette/HHQTemplate/diffusion.C ./diffusion.C
cp -n /sphenix/user/jouellette/HHQTemplate/params.txt ./params.txt

mkdir -p ./log

for (( i=${1}; ${i}<${2}; i++))
do
  en=$(($i-$1))

  cp -rn /sphenix/user/jouellette/HHQTemplate/inited_specified_template ./event$i
  mkdir -p ./log/job_$en

  cd ./event$i
  cp -n /direct/phenix+u/jouellette/TGlauberMC/initedFiles_${sys}/event$i.dat ./input/inited.dat #TODO change me!!!
  cp -n /direct/phenix+u/jouellette/TGlauberMC/initedFiles_${sys}/event$i.root ./quarkdist.root #TODO change me!!!
  cp -n /sphenix/user/jouellette/HHQTemplate/params.txt ./data/params.txt #TODO change me!!!
  cp -n /sphenix/user/jouellette/HHQTemplate/heavy_quark_pt.root ./ # if you have your own pT distribution, TODO change me too!!
  cd ../
  echo "" >> submit_events.job
  echo "Arguments = event$i $i $en $3 $4 $5" >> submit_events.job
  echo "Queue 1" >> submit_events.job
done

echo "All done! Be sure to check submit_runs.job script for potential changes."
